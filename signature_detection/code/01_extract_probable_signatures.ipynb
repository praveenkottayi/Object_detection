{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from matplotlib.pyplot import imshow\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"path given : \" + str(sys.argv[1:]))\n",
    "#x = (sys.argv[1:])\n",
    "working_directory = !pwd \n",
    "x =  working_directory[0] + \"/Test Documents/\"\n",
    "path = x[0]\n",
    "y = os.listdir(x[0])\n",
    "images = []\n",
    "for i in y :\n",
    "\tif i.split('.')[-1].lower() == \"png\" or i.split('.')[-1].lower() == \"jpg\" or i.split('.')[-1].lower() == \"jpeg\":\n",
    "\t\timages.append(i)\n",
    "\t\t#print(i)\n",
    "#print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "\n",
    "for i in images :\n",
    "\ttry:\n",
    "\t\t##########################################################################\n",
    "\t\timage_name = i   #\"01.png\"\n",
    "\t\tprint(\"processing....\" + image_name )\n",
    "\t\t#path = x[0]\n",
    "\t\t#print(path)\n",
    "\t\tdestination = path + \"/DETECTED/\" + str(image_name.split('.')[0]) +\"/\"\n",
    "\t\t#print(destination)\n",
    "\t\tdestination_prob_stamps = path + \"/DETECTED/\"  + str(image_name.split('.')[0]) +\"/prob_signature/\"\n",
    "\t\t#print(destination_prob_stamps)\n",
    "\n",
    "\t\t#image_name = arg\n",
    "\t\timg_path = path + \"/\" +  image_name  \n",
    "\n",
    "\t\tif not os.path.exists(destination):\n",
    "\t\t\tos.makedirs(destination)\n",
    "\n",
    "\t\tif not os.path.exists(destination_prob_stamps):\n",
    "\t\t\tos.makedirs(destination_prob_stamps)    \n",
    "\t\t   \n",
    "\t\t#############################################################################\n",
    "\t\t#                             processing part \n",
    "\t\t#############################################################################\n",
    "\t\t# read image  \n",
    "\t\timg = cv2.imread(img_path, 0)\n",
    "\t\t#plt.imshow(img)\n",
    "\t\tret, thresh = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY)       # VARIABLE 1 \n",
    "\t\t# Otsu's thresholding\n",
    "\t\t#ret, thresh = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\t\t##############################\n",
    "\t\tcv2.imwrite( destination +\"thresh.jpg\", thresh )\n",
    "\n",
    "\t\t# connected component labeling and filtering based on size\n",
    "\t\tsize_threshold = (img.shape[0]*img.shape[1])\n",
    "\t\t\n",
    "\t\t#find all your connected components (white blobs in your image)\n",
    "\t\tnb_components, output, stats, centroids = cv2.connectedComponentsWithStats(cv2.bitwise_not(thresh), connectivity=8)\n",
    "\t\tsizes = stats[1:, -1]; nb_components = nb_components - 1\n",
    "\n",
    "\t\t# minimum & maximum size of particles we want to keep (number of pixels)\n",
    "\t\tmin_size = 100  # VARIABLE 2 \n",
    "\t\tmax_size = size_threshold*0.7 # VARIABLE 3 \n",
    "\t\timg2 = np.zeros((output.shape))\n",
    "\t\t\n",
    "\t\t#for every component in the image, you keep it only if it's above min_size & less than max_size\n",
    "\t\tfor i in range(0, nb_components):\n",
    "\t\t\tif sizes[i] >= min_size and sizes[i] <= max_size:\n",
    "\t\t\t\timg2[output == i + 1] = 255\n",
    "\t\t \n",
    "\t\tcv2.imwrite( destination+ \"connected_components.jpg\", (img2) )  \n",
    "\t\t\n",
    "\t\t# blurring the image to combine nearby blobs\n",
    "\t\tfilter_size = 9 # 21   # VARIABLE 4 \n",
    "\t\tbb_image = cv2.GaussianBlur(img2,(filter_size,filter_size),0)\n",
    "\t\t\n",
    "\t\t# find contours and get the external one\n",
    "\t\timage, contours, hier = cv2.findContours(bb_image.astype('uint8'), cv2.RETR_TREE,\n",
    "\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\t\t# drawing bounding boxes around probable blobs of stamp\n",
    "\n",
    "\t\t# h & w ... based on actual image ratio\n",
    "\n",
    "\t\tstamp_list = []\n",
    "\t\tfor c in contours:\n",
    "\t\t\t# get the bounding rect\n",
    "\t\t\tx, y, w, h = cv2.boundingRect(c)\n",
    "\t\t\t#print(x , \" \", y , \" \", w , \" \",h)\n",
    "\t\t\tif (h>img.shape[0]*.05 and h<img.shape[0]*0.7) and (w>img.shape[1]*0.05 and w<img.shape[1]*0.7) :  # # VARIABLE 4 \n",
    "\t\t\t\t#print(x , \" \", y , \" \", w , \" \",h)\n",
    "\t\t\t\t# draw a rectangle to visualize \n",
    "\t\t\t\tcv2.rectangle(bb_image, (x, y), (x+w, y+h),(255, 255, 0), 2)\n",
    "\t\t\t\tstamp_list.append([y,y+h,x,x+w])\n",
    "\n",
    "\t\tcv2.imwrite( destination+ \"blur.jpg\", (bb_image) )\t\t\n",
    "\n",
    "\t\t\n",
    "\t\t##########################################################################\n",
    "\t\t# 2nd level of scanning for signature by increasing filter size of blur \n",
    "\t\t# \n",
    "\t\t##########################################################################\n",
    "\t\t# blurring the image to combine nearby blobs\n",
    "\t\tfilter_size = 51 # 21   # VARIABLE 4 \n",
    "\t\tbb_image_2 = cv2.GaussianBlur(img2,(filter_size,filter_size),0)\n",
    "\t\t\n",
    "\t\t# find contours and get the external one\n",
    "\t\timage, contours, hier = cv2.findContours(bb_image_2.astype('uint8'), cv2.RETR_TREE,\n",
    "\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\t\t# drawing bounding boxes around probable blobs of stamp\n",
    "\n",
    "\t\t# h & w ... based on actual image ratio\n",
    "\n",
    "\t\t#stamp_list = []\n",
    "\t\tfor c in contours:\n",
    "\t\t\t# get the bounding rect\n",
    "\t\t\tx, y, w, h = cv2.boundingRect(c)\n",
    "\t\t\t#print(x , \" \", y , \" \", w , \" \",h)\n",
    "\t\t\tif (h>img.shape[0]*.05 and h<img.shape[0]*0.7) and (w>img.shape[1]*0.05 and w<img.shape[1]*0.7) :  # # VARIABLE 4 \n",
    "\t\t\t\t#print(x , \" \", y , \" \", w , \" \",h)\n",
    "\t\t\t\t# draw a rectangle to visualize \n",
    "\t\t\t\tcv2.rectangle(bb_image_2, (x, y), (x+w, y+h),(255, 255, 0), 2)\n",
    "\t\t\t\tstamp_list.append([y,y+h,x,x+w])\n",
    "\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t##########################################################################\n",
    "\t\t# define the list of boundaries for COLOR BLOBS\n",
    "\t\t# Color filter : filter probable stamps based on color\n",
    "\t\t##########################################################################\n",
    "\t\timg = cv2.imread(img_path)\n",
    "\t\thsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\t\t\t\n",
    "\t\tlower_color_spectrum = np.array([0, 100, 100])\n",
    "\t\tupper_color_spectrum = np.array([360, 255, 255])\n",
    "\t\t\t\n",
    "\t\tmask = cv2.inRange(hsv, lower_color_spectrum, upper_color_spectrum)\n",
    "\t\tres = cv2.bitwise_and(img,img, mask= mask)\n",
    "\n",
    "\t\timg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\t\timg_c = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\t\tsize_threshold = (img.shape[0]*img.shape[1])\n",
    "\n",
    "\t\t#find all your connected components (white blobs in your image)\n",
    "\t\tnb_components, output, stats, centroids = cv2.connectedComponentsWithStats((mask), connectivity=8)\n",
    "\t\tsizes = stats[1:, -1]; nb_components = nb_components - 1\n",
    "\n",
    "\t\t# minimum & maximum size of particles we want to keep (number of pixels)\n",
    "\n",
    "\t\tmin_size = 10    # VARIABLE 4 \n",
    "\t\tmax_size = size_threshold*0.8 # VARIABLE 4 \n",
    "\n",
    "\t\timg2 = np.zeros((output.shape))\n",
    "\t\t#for every component in the image, you keep it only if it's above min_size & less than max_size\n",
    "\t\tfor i in range(0, nb_components):\n",
    "\t\t\tif sizes[i] >= min_size and sizes[i] <= max_size:\n",
    "\t\t\t\timg2[output == i + 1] = 255\n",
    "\n",
    "\t\tfilter_size = 15 #  # VARIABLE 4 \n",
    "\t\tbb_image = cv2.GaussianBlur(img2,(filter_size,filter_size),0)\n",
    "\n",
    "\t\t# find contours and get the external one\n",
    "\t\timage, contours, hier = cv2.findContours(bb_image.astype('uint8'), cv2.RETR_TREE,\n",
    "\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\t\t# h & w ... based on actual image ratio\n",
    "\n",
    "\t\t#stamp_list = []\n",
    "\t\tfor c in contours:\n",
    "\t\t\t# get the bounding rect\n",
    "\t\t\tx, y, w, h = cv2.boundingRect(c)\n",
    "\t\t\t#print(x , \" \", y , \" \", w , \" \",h)\n",
    "\t\t\tif (h>img.shape[0]*.05 and h<img.shape[0]*0.9) and (w>img.shape[1]*0.1 and w<img.shape[1]*0.9) :  # # VARIABLE 4 \n",
    "\t\t\t\t#print(x , \" \", y , \" \", w , \" \",h)\n",
    "\t\t\t\t# draw a rectangle to visualize \n",
    "\t\t\t\tcv2.rectangle(bb_image, (x, y), (x+w, y+h),(255, 255, 0), 2)\n",
    "\t\t\t\tstamp_list.append([y,y+h,x,x+w])\n",
    "\t\tcv2.imwrite( destination+ \"color_mask.jpg\", (res) )\n",
    "\t\tcv2.imwrite( destination+ \"color_bb.jpg\", (bb_image) )\n",
    "\n",
    "\t\t# to save black nd white part as probable signature\n",
    "\t\timg_c = thresh\n",
    "\n",
    "\t\tfor i in range (0,len(stamp_list)):\n",
    "\t\t\textracted_img1 = img_c[stamp_list[i][0]:stamp_list[i][1] ,stamp_list[i][2]:stamp_list[i][3]]\n",
    "\t\t\tcv2.imwrite(destination_prob_stamps+str(i)+\".png\",extracted_img1)\n",
    "\t\t\n",
    "\t\n",
    "\texcept :\n",
    "\t\tprint(\".....................\")\n",
    "     \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
